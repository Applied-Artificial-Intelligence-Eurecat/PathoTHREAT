{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Vs26-8W2Sqf"
      },
      "outputs": [],
      "source": [
        "!pip3 install -q langchain\n",
        "!pip3 install -q huggingface_hub\n",
        "!pip3 install -q sentence_transformers\n",
        "!pip3 install -q chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT9Ba95p62ih"
      },
      "outputs": [],
      "source": [
        "huggingface_hub.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-muhZ8Z52Dn_"
      },
      "source": [
        "# Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnaQb1uJ1yvJ"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUih7DMY2PDo"
      },
      "outputs": [],
      "source": [
        "loader = TextLoader(\"article.txt\")\n",
        "doc = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gi0UrvM4ZFA"
      },
      "source": [
        "# Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_-bpwv94cz5"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXaF45sn4ADY"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 600, chunk_overlap = 100)\n",
        "all_splits = text_splitter.split_documents(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRJlFdj6XxJ"
      },
      "source": [
        "# Storing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbeTEt6f6ZkJ"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVt2J6pl6dy6"
      },
      "outputs": [],
      "source": [
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_IPl16I7r6B"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=hf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYpFFixx8hd5"
      },
      "source": [
        "# Retrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_dHrmZP8kgB"
      },
      "outputs": [],
      "source": [
        "question = \"What happened?\"\n",
        "docs = vectorstore.similarity_search(question)\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaPivuWX9iCg"
      },
      "source": [
        "# Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm6nIS-h9qeZ"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline, HuggingFaceHub\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbqpGdeZ9Tex"
      },
      "outputs": [],
      "source": [
        "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "pipe = pipeline(\n",
        "    \"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=200\n",
        "    )\n",
        "hf = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nt6z8P8z-8D7"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLNdzBZx-86y"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(hf,retriever=vectorstore.as_retriever())\n",
        "qa_chain({\"query\": question})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}